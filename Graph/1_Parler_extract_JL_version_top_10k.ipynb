{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyterlab version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and process data into nodes and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bbwzfN7fJ2A6"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import gzip\n",
    "from pprint import pprint\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumes that the data files are in a subfolder called 'Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Alex\n",
    "# unzips the file and goes through it\n",
    "# 1 line is 1 post\n",
    "\n",
    "data_path = '../Data/'  #change dir to your project folder\n",
    "filename = os.path.join(data_path, 'processed.1850k.jsonl.gz')\n",
    "\n",
    "def iterate_posts():\n",
    "    with gzip.open(filename, 'rb') as fd:\n",
    "      for line in fd:\n",
    "          yield json.loads(line)\n",
    "            \n",
    "gen = iterate_posts()\n",
    "#next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "teCfv4UmgmA4"
   },
   "outputs": [],
   "source": [
    "# Collect a set of all usernames found in posts\n",
    "# Using posts.pickle.gz allows 1 line = 1 name\n",
    "# This file breaks replies off from the parent post\n",
    "# so that we don't have to worry about parsing multiple\n",
    "# names in one line.\n",
    "# Once we haved a list of each username from each post,\n",
    "# remove duplicates to get a full list of unique usernames\n",
    "from collections import Counter\n",
    "\n",
    "filename2 = os.path.join(data_path, 'posts.pickle.gz')\n",
    "\n",
    "single_posts = pickle.load(gzip.open(filename2, 'rb'))\n",
    "nodes = []\n",
    "for post in single_posts.values():\n",
    "    nodes.append(post['author'].replace(\" \", \"_\")) # Need to remove spaces in a few names\n",
    "    \n",
    "user_post_count = Counter(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10k = user_post_count.most_common(10001)\n",
    "top_10k = top_10k[1:10001]\n",
    "len(top_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [item[0] for item in top_10k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyz-m_86oAzB"
   },
   "outputs": [],
   "source": [
    "def get_list_of_users(post):\n",
    "    \"\"\" \n",
    "    Extract all usernames from each post\n",
    "\n",
    "    Note:\n",
    "        There can be None, one, or more usernames in a post.\n",
    "     \n",
    "     Args:\n",
    "         post (dict): Yielded by iterate_posts()\n",
    "\n",
    "    Attributes:\n",
    "        users (dict): Used to collect usernames \n",
    "        \n",
    "    Returns:\n",
    "        users: Tuple of usernames from each post. Can contain any number of usernames.\n",
    "    \"\"\"    \n",
    "\n",
    "    users = []\n",
    "    try:\n",
    "        for post_item in post['posts']:                \n",
    "            users.append(post_item['author_username'].replace(\" \", \"_\"))\n",
    "    except KeyError:\n",
    "        if len(users)>1:\n",
    "            return tuple(users) #list of usernames from ONE(1) post\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect a list of tuples of of length 2 or more usernames from posts\n",
    "# Filters out lists of None and lists with only 1 user. This is why 'minimum_posts' of 2 is unneeded.\n",
    "# The exception is triggered by reaching the end of the JSONL file.\n",
    "def get_edges():\n",
    "    user_tuple_list=[]\n",
    "    edges_temp=[]\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            user_tuple_list.append(get_list_of_users(next(gen))) \n",
    "    except:  \n",
    "        user_tuple_list = list(set(user_tuple_list))\n",
    "        for user_list in user_tuple_list:\n",
    "#            if user_list != None and len(user_list)>1:\n",
    "            if user_list != None:\n",
    "                edges_temp.append(user_list)\n",
    "            else:\n",
    "                continue\n",
    "        print(\"Complete\")\n",
    "        return edges_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_edges(all_edges):\n",
    "    \"\"\"  \n",
    "    Split tuples into tuples of length 2 and remove duplicates.\n",
    "\n",
    "    Args:\n",
    "        all_edges (list of tuples): These tuples vary in length.\n",
    "\n",
    "    Attributes: \n",
    "        user_list (list): Keeps tuples generated/passed by for loop.\n",
    "        \n",
    "    Returns:\n",
    "        user_list (list of tuples): Each tuple is of length 2 and duplicates are removed.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    user_list = []\n",
    "    \n",
    "    for user_tuple in all_edges:\n",
    "        if len(user_tuple)==2:\n",
    "            user_list.append(user_tuple)\n",
    "        else:\n",
    "            for username in user_tuple:\n",
    "                if username!=user_tuple[0]:\n",
    "                    user_list.append((user_tuple[0],username))\n",
    "                else:\n",
    "                    continue\n",
    "            continue\n",
    "    return list(set(user_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_low_posters(edges):\n",
    "    temp_list = []\n",
    "    for username_tuple in edges:\n",
    "        name_list = []\n",
    "        for username in username_tuple:\n",
    "            if username in nodes:\n",
    "                name_list.append(username)\n",
    "            else:\n",
    "                pass\n",
    "        if len(name_list)>1:\n",
    "            temp_list.append(tuple(name_list))\n",
    "        else:\n",
    "            pass\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges = get_edges()\n",
    "print(f'all_edges is a {type(all_edges)} of {type(all_edges[0])} containing {type(all_edges[0][0])}')\n",
    "len(all_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all elements of edges to be tuples of length 2 with duplicates removed.\n",
    "edges = split_edges(all_edges)\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_posters = remove_low_posters(edges)\n",
    "len(high_posters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(high_posters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_posters[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the nodes and edges to a file\n",
    "# TODO: Write code to read in the files to the appropriate variables so that we don't have to run all of the above code again\n",
    "graph_path = 'Graph/'\n",
    "\n",
    "open(os.path.join(graph_path,'edges.txt'), 'w').write('\\n'.join('%s %s' % x for x in high_posters))\n",
    "#open(os.path.join(graph_path,'edges with low posters removed.txt'), 'w').write('\\n'.join('%s %s' % x for x in high_posters))\n",
    "open(os.path.join(graph_path,'nodes.txt'), 'w').write('\\n'.join('%s' % x for x in nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Parler working.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
