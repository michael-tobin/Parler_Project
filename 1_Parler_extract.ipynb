{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "bbwzfN7fJ2A6"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import gzip\n",
    "from pprint import pprint\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If using Google Colab, use the next three cells to import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eT3Uz2tqJT6o",
    "outputId": "9c3f0f6c-caad-4827-bd09-3a38d646039d"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-98e9ad21a45a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mroot_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gdrive/My Drive/Parler Data/'\u001b[0m  \u001b[0;31m#change dir to your project folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "root_path = 'gdrive/My Drive/Parler Data/'  #change dir to your project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jM5jIKDGJgS8"
   },
   "outputs": [],
   "source": [
    "# Written by Alex\n",
    "# unzips the file and goes through it\n",
    "# 1 line is 1 post\n",
    "filename = os.path.join(root_path, 'processed.1850k.jsonl.gz')\n",
    "\n",
    "def iterate_posts():\n",
    "    with gzip.open(filename, 'rb') as fd:\n",
    "      for line in fd:\n",
    "          yield json.loads(line)\n",
    "            \n",
    "gen = iterate_posts()\n",
    "#next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect a set of all usernames found in posts\n",
    "# Using posts.pickle.gz allows 1 line = 1 name\n",
    "# This file breaks replies off from the parent post\n",
    "# so that we don't have to worry about parsing multiple\n",
    "# names in one line.\n",
    "# Once we haved a list of each username from each post,\n",
    "# remove duplicates to get a full list of unique usernames\n",
    "from collections import Counter\n",
    "\n",
    "filename2 = os.path.join(root_path, 'posts.pickle.gz')\n",
    "single_posts = pickle.load(gzip.open(filename2, 'rb'))\n",
    "nodes = []\n",
    "for post in single_posts.values():\n",
    "    nodes.append(post['author'])\n",
    "    \n",
    "user_post_count = Counter(nodes)\n",
    "nodes = set(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If using Jupyter Lab, use the next two cells to import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumes that the data files are in the same folder as the .ipynb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Alex\n",
    "# unzips the file and goes through it\n",
    "# 1 line is 1 post\n",
    "filename = 'processed.1850k.jsonl.gz'\n",
    "def iterate_posts():\n",
    "    with gzip.open(filename, 'rb') as fd:\n",
    "      for line in fd:\n",
    "          yield json.loads(line)\n",
    "            \n",
    "gen = iterate_posts()\n",
    "#next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "teCfv4UmgmA4"
   },
   "outputs": [],
   "source": [
    "# Collect a set of all usernames found in posts\n",
    "# Using posts.pickle.gz allows 1 line = 1 name\n",
    "# This file breaks replies off from the parent post\n",
    "# so that we don't have to worry about parsing multiple\n",
    "# names in one line.\n",
    "# Once we haved a list of each username from each post,\n",
    "# remove duplicates to get a full list of unique usernames\n",
    "from collections import Counter\n",
    "\n",
    "filename2 = 'posts.pickle.gz'\n",
    "single_posts = pickle.load(gzip.open(filename2, 'rb'))\n",
    "nodes = []\n",
    "for post in single_posts.values():\n",
    "    nodes.append(post['author'])\n",
    "    \n",
    "user_post_count = Counter(nodes)\n",
    "nodes = list(set(nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data\n",
    "### Everything after here is platform agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dictionary of user post frequencies by username sorted by post frequencies, descending\n",
    "# The sorting isn't really necessary for the next part,\n",
    "# it just makes it easier to spot check manually\n",
    "\n",
    "sorted_user_post_count=sorted(dict(user_post_count).items(), key=lambda item:item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('@Private User', 37703)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_user_post_count[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get users who only posted a certain number of times\n",
    "# The number of posts may be adjusted to meet filtering needs\n",
    "\n",
    "# CHANGE THIS VARIABLE TO ADJUST USER FILTERING\n",
    "minimum_posts = 2 \n",
    "\n",
    "low_posters = [user for user, freq in sorted_user_post_count if freq<minimum_posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107823"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(low_posters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "hyz-m_86oAzB"
   },
   "outputs": [],
   "source": [
    "def get_list_of_users(post):\n",
    "    \"\"\" \n",
    "    Extract all usernames from each post\n",
    "\n",
    "    Note:\n",
    "        There can be None, one, or more usernames in a post.\n",
    "     \n",
    "     Args:\n",
    "         post (dict): Yielded by iterate_posts()\n",
    "\n",
    "    Attributes:\n",
    "        users (dict): Used to collect usernames \n",
    "        \n",
    "    Returns:\n",
    "        users: Tuple of usernames from each post. Can contain any number of usernames.\n",
    "    \"\"\"    \n",
    "\n",
    "    users = []\n",
    "    try:\n",
    "        for post_item in post['posts']:                \n",
    "            users.append(post_item['author_username'])\n",
    "    except KeyError:\n",
    "        return users #list of usernames from ONE(1) post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o8Gl5tqEvWrW",
    "outputId": "8a2bf2d2-044c-4af9-d77b-f374214c0aa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while true\n",
      "for user in list\n",
      "else\n",
      "while true\n",
      "for user in list\n",
      "else\n",
      "for user in list\n",
      "else\n",
      "while true\n",
      "for user in list\n",
      "else\n",
      "while true\n",
      "for user in list\n",
      "else\n",
      "for user in list\n",
      "else\n",
      "while true\n",
      "for user in list\n",
      "else\n",
      "while true\n",
      "for user in list\n",
      "else\n",
      "while true\n",
      "for user in list\n",
      "else\n",
      "while true\n",
      "for user in list\n",
      "else\n",
      "while true\n",
      "for user in list\n",
      "else\n",
      "while true\n",
      "for user in list\n",
      "else\n",
      "while true\n",
      "for user in list\n",
      "else\n",
      "while true\n",
      "for user in list\n",
      "else\n",
      "while true\n",
      "for user in list\n",
      "else\n",
      "while true\n",
      "for user in list\n",
      "else\n",
      "while true\n",
      "for user in list\n",
      "else\n",
      "while true\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Collect a list of tuples of of length 2 or more usernames from posts\n",
    "# The exception is triggered by reaching the end of the JSONL file.\n",
    "\n",
    "edges_temp=[]\n",
    "all_edges=[]\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        print(\"while true\")\n",
    "            # start new testing section\n",
    "        temp_list = get_list_of_users(next(gen))\n",
    "        \n",
    "        for username in temp_list:\n",
    "            print(\"for user in list\")\n",
    "            if username == None:\n",
    "                print('None')\n",
    "                pass\n",
    "            elif username in low_posters:\n",
    "                print('if user in low')\n",
    "                temp_list.remove(username)\n",
    "                low_posters.remove(username)\n",
    "            else:\n",
    "                print('else')\n",
    "                edges_temp.append(username)\n",
    "                # end new testing section\n",
    "#        edges_temp.append(get_list_of_users(next(gen))) # Append list to list, for list of lists\n",
    "except:  \n",
    "    print(\"excepting\")\n",
    "    #edges_temp=list((edges_temp))\n",
    "    for user_tuple in edges_temp:\n",
    "        if user_tuple != None and len(user_tuple)>1:\n",
    "            all_edges.append(user_tuple)\n",
    "        else:\n",
    "            pass #was continue\n",
    "    del edges_temp #free up memory\n",
    "    print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@TD78',\n",
       " '@Joemachesky',\n",
       " '@BobbyVociferous',\n",
       " '@CounterGlobalist',\n",
       " '@jakeroedel',\n",
       " '@WilburC',\n",
       " '@BeachMilk',\n",
       " '@Prosperwithlu',\n",
       " '@WarriorGirl454',\n",
       " '@WeLoveTrump',\n",
       " '@MeyersMike',\n",
       " '@cjtruth',\n",
       " '@TruthReallyMatters',\n",
       " '@StormIsUponUs',\n",
       " '@ThomasFox',\n",
       " '@dfwactivist',\n",
       " '@WeLoveTrump']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_low_posters(all_edges):\n",
    "    temp_list=[]\n",
    "    for username_list in all_edges:\n",
    "        name_list=[]\n",
    "        for username in username_list:\n",
    "            if username not in low_posters:\n",
    "                name_list.append(username)\n",
    "            else: \n",
    "                pass\n",
    "        temp_list.append(name_list)\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_singles(all_edges):\n",
    "    for user_tuple in all_edges:\n",
    "        if len(user_tuple)<2:\n",
    "            all_edges.remove(user_tuple)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_edges=all_edges[10000:50000]\n",
    "len(some_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-cab18be8191e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmost_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_low_posters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-2da2a7f74454>\u001b[0m in \u001b[0;36mremove_low_posters\u001b[0;34m(all_edges)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mname_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0musername\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musername_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0musername\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow_posters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                 \u001b[0mname_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "most_edges = remove_low_posters(some_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(most_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161110"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@riseupmelbourne', '@BitterPoisonOfTheSoul']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_edges(all_edges):\n",
    "    \"\"\"  \n",
    "    Split tuples into tuples of length 2 and remove duplicates.\n",
    "\n",
    "    Args:\n",
    "        all_edges (list of tuples): These tuples vary in length.\n",
    "\n",
    "    Attributes: \n",
    "        user_list (list): Keeps tuples generated/passed by for loop.\n",
    "        \n",
    "    Returns:\n",
    "        user_list (list of tuples): Each tuple is of length 2 and duplicates are removed.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    user_list = []\n",
    "    \n",
    "    for user_tuple in all_edges:\n",
    "        if len(user_tuple)==2:\n",
    "            user_list.append(user_tuple)\n",
    "        else:\n",
    "            for username in user_tuple:\n",
    "                if username!=user_tuple[0]:\n",
    "                    user_list.append((user_tuple[0],username))\n",
    "                else:\n",
    "                    continue\n",
    "            continue\n",
    "    return list(set(user_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all elements of edges to be tuples of length 2 with duplicates removed.\n",
    "edges = split_edges(all_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 229235 edges with 458470 usernames to check.\n",
      "This has to be checked against 148904 usernames in low posters.\n",
      "That means 68268016880 clock cycles.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(edges)} edges with {len(edges)*2} usernames to check.\")\n",
    "print(f\"This has to be checked against {len(low_posters)} usernames in low posters.\")\n",
    "print(f\"That means {(len(edges)*2)*len(low_posters)} clock cycles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_edges[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove from edges those users who only posted a few times\n",
    "edges = [tup for tup in edges if not any(i in tup for i in low_posters)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(nodes)} individual users.')\n",
    "print(f'There are {len(low_posters)} users who made less than {minimum_posts} posts who can be removed.')\n",
    "print(f'That will leave us with {len(edges)} users to graph.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the nodes and edges to a file\n",
    "# TODO: Write code to read in the files to the appropriate variables so that we don't have to run all of the above code again\n",
    "open('edges.txt', 'w').write('\\n'.join('%s %s' % x for x in edges))\n",
    "open('nodes.txt', 'w').write('\\n'.join('%s' % x for x in nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(nodes)} nodes in the graph.')\n",
    "print(f'There are {len(all_edges)} total edges, but this includes duplicates and multiple replies to one post.')\n",
    "print(f'There are {len(edges)} edges once we split the posts and remove duplicates.')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and process the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lda_t41xMEA9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = [G.subgraph(c).copy() for c in nx.connected_components(G)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=sorted(S, key=len, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=S[1]\n",
    "# S[1] should have 21 nodes\n",
    "# S[0] is the big one that takes forever to plot\n",
    "len(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {sub.number_of_nodes()} nodes, and')\n",
    "print(f'There are {sub.number_of_edges()} edges in the subgraph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(sub, node_size=100, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Degree centrality](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.degree_centrality.html#networkx.algorithms.centrality.degree_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: sort this dict by value for readability\n",
    "dc = nx.degree_centrality(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kernighanâ€“Lin bipartition algorithm](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.kernighan_lin.kernighan_lin_bisection.html#networkx.algorithms.community.kernighan_lin.kernighan_lin_bisection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community import kernighan_lin_bisection\n",
    "klb = kernighan_lin_bisection(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: adjust the printing of this for readability\n",
    "klb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Greedy Modularity Community](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.modularity_max.greedy_modularity_communities.html#networkx.algorithms.community.modularity_max.greedy_modularity_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "gmc = greedy_modularity_communities(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: adjust the printing of this for readability\n",
    "gmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the graph to a GXF file for later use\n",
    "# Can be imported into Gephi\n",
    "nx.write_gexf(sub, \"subgraph.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Parler working.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
